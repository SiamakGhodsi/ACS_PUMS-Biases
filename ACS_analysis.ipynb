{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99e3bdb",
   "metadata": {},
   "source": [
    "# ACS analytics\n",
    "In this notebok we provide some statistic about and apply some preprocesses on ACS-Census data.\n",
    " \n",
    " - Analytics would be correlation of target(Income) with prtected attributes of <b>Race</b>, <b>Age</b>, <b>Sex</b> which to see if there is any bias regarding these protected attributes or not\n",
    " - Furthermore, it will be held on 4 most populated states of <i><b>California</b></i>, <i><b>Florida</b></i>, <i><b>Texas</b></i>, and <i><b>New York</b></i> and the whole <i><b>US<i/></b> for the year 2020 and a 5 years range from 2013-2018\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment, ACSIncome\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401990c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "# acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "# features, label, group = ACSEmployment.df_to_numpy(acs_data)\n",
    "#\n",
    "#\n",
    "# X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "#     features, label, group, test_size=0.2, random_state=0)\n",
    "#\n",
    "# ###### Your favorite learning algorithm here #####\n",
    "# model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "# model.fit(X_train, y_train)\n",
    "#\n",
    "# yhat = model.predict(X_test)\n",
    "#\n",
    "# white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "# black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "#\n",
    "# # Equality of opportunity violation: 0.0455\n",
    "# white_tpr - black_tpr\n",
    "\n",
    "\n",
    "# acs_tx = data_source.get_data(states=[\"CT\"], download=True)\n",
    "# tx_features, tx_label, tx_group = ACSEmployment.df_to_numpy(acs_tx)\n",
    "#\n",
    "# features, label, group = ACSEmployment.df_to_numpy(acs_tx)\n",
    "# X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "#     tx_features, tx_label, tx_group, test_size=0.2, random_state=0)\n",
    "#\n",
    "# model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "# model.fit(X_train, y_train)\n",
    "#\n",
    "# yhat = model.predict(X_test)\n",
    "# white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "# black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "#\n",
    "# # Equality of opportunity violation: 0.0397\n",
    "# white_tpr - black_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "ca_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "sd_data = data_source.get_data(states=[\"SD\"], download=True)\n",
    "ca_features, ca_labels, ca_group = ACSIncome.df_to_numpy(ca_data)\n",
    "sd_features, sd_labels, sd_group = ACSIncome.df_to_numpy(sd_data)\n",
    "\n",
    "# Plug-in your method for tabular datasets\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# Train on CA data\n",
    "model.fit(ca_features, ca_labels)\n",
    "\n",
    "# Test on SD data\n",
    "s1= model.score(sd_features, sd_labels)\n",
    "\n",
    "# get fairness\n",
    "yhat=model.predict(sd_features)\n",
    "white_tpr = np.mean(yhat[(sd_labels == 1) & (sd_group == 1)])\n",
    "black_tpr = np.mean(yhat[(sd_labels == 1) & (sd_group == 2)])\n",
    "non_white_tpr = np.mean(yhat[(sd_labels == 1) & (sd_group != 1)])\n",
    "\n",
    "print('accuracy: model trained on CA data and tested on SD state:' + str(s1))\n",
    "print('also TPR of SD for 3 groups: \\n\\t1-white group: '+ str(white_tpr)+'\\n\\t2-black_group: '\n",
    "      + str(black_tpr)+ '\\n\\t3-all non whites:'+ str(non_white_tpr))\n",
    "\n",
    "\n",
    "########################### Spatial Distribution shift\n",
    "X_train_ca, X_test_ca, y_train_ca, y_test_ca, group_train_ca, group_test_ca = train_test_split(\n",
    "    ca_features, ca_labels, ca_group, test_size=0.2, random_state=0)\n",
    "\n",
    "model.fit(X_train_ca, y_train_ca)\n",
    "\n",
    "s2= model.score(X_test_ca, y_test_ca)\n",
    "\n",
    "yhat = model.predict(X_test_ca)\n",
    "\n",
    "white_tpr = np.mean(yhat[(y_test_ca == 1) & (group_test_ca == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test_ca == 1) & (group_test_ca == 2)])\n",
    "non_white_tpr = np.mean(yhat[(y_test_ca == 1) & (group_test_ca != 1)])\n",
    "\n",
    "print('\\naccuracy: model trained and tested on CA:' + str(s2))\n",
    "print('also TPR of SD for 3 groups: \\n\\t1-white group: '+ str(white_tpr)+'\\n\\t2-black_group: '\n",
    "      + str(black_tpr)+ '\\n\\t3-all non whites:'+ str(non_white_tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e766d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "ca_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "sd_data = data_source.get_data(states=[\"FL\"], download=True)\n",
    "ca_features, ca_labels, ca_group = ACSIncome.df_to_numpy(ca_data)\n",
    "sd_features, sd_labels, sd_group = ACSIncome.df_to_numpy(sd_data)\n",
    "\n",
    "# Plug-in your method for tabular datasets\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# Train on CA data\n",
    "model.fit(ca_features, ca_labels)\n",
    "\n",
    "# Test on SD data\n",
    "s1= model.score(fl_features, fl_labels)\n",
    "\n",
    "# get fairness\n",
    "yhat=model.predict(sd_features)\n",
    "white_tpr = np.mean(yhat[(fl_labels == 1) & (fl_group == 1)])\n",
    "black_tpr = np.mean(yhat[(fl_labels == 1) & (fl_group == 2)])\n",
    "non_white_tpr = np.mean(yhat[(fl_labels == 1) & (fl_group != 1)])\n",
    "\n",
    "print('accuracy: model trained on CA data and tested on Florida state:' + str(s1))\n",
    "print('also TPR of FL for 3 groups: \\n\\t1-white group: '+ str(white_tpr)+'\\n\\t2-black_group: '\n",
    "      + str(black_tpr)+ '\\n\\t3-all non whites:'+ str(non_white_tpr))\n",
    "\n",
    "\n",
    "########################### Spatial Distribution shift\n",
    "X_train_ca, X_test_ca, y_train_ca, y_test_ca, group_train_ca, group_test_ca = train_test_split(\n",
    "    ca_features, ca_labels, ca_group, test_size=0.2, random_state=0)\n",
    "\n",
    "model.fit(X_train_ca, y_train_ca)\n",
    "\n",
    "s2= model.score(X_test_ca, y_test_ca)\n",
    "\n",
    "yhat = model.predict(X_test_ca)\n",
    "\n",
    "white_tpr = np.mean(yhat[(y_test_ca == 1) & (group_test_ca == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test_ca == 1) & (group_test_ca == 2)])\n",
    "non_white_tpr = np.mean(yhat[(y_test_ca == 1) & (group_test_ca != 1)])\n",
    "\n",
    "print('\\naccuracy: model trained and tested on CA:' + str(s2))\n",
    "print('also TPR of SD for 3 groups: \\n\\t1-white group: '+ str(white_tpr)+'\\n\\t2-black_group: '\n",
    "      + str(black_tpr)+ '\\n\\t3-all non whites:'+ str(non_white_tpr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
